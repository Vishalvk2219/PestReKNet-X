{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T00:37:25.507131Z",
     "iopub.status.busy": "2024-10-24T00:37:25.506783Z",
     "iopub.status.idle": "2024-10-24T00:39:05.149018Z",
     "shell.execute_reply": "2024-10-24T00:39:05.147920Z",
     "shell.execute_reply.started": "2024-10-24T00:37:25.507092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "img_height, img_width = 224, 224\n",
    "epochs = 40\n",
    "num_classes = 22 \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder('/kaggle/input/pest-training/Training_Data/Training_Data', transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder('/kaggle/input/pest-training/Validation_Data/Validation_Data', transform=val_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-24T00:39:05.154965Z",
     "iopub.status.busy": "2024-10-24T00:39:05.154501Z",
     "iopub.status.idle": "2024-10-24T00:39:05.188008Z",
     "shell.execute_reply": "2024-10-24T00:39:05.187099Z",
     "shell.execute_reply.started": "2024-10-24T00:39:05.154915Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the KANLinear class\n",
    "class KANLinear(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        out_features,\n",
    "        grid_size=10,\n",
    "        spline_order=4,\n",
    "        scale_noise=0.1,\n",
    "        scale_base=1.0,\n",
    "        scale_spline=1.0,\n",
    "        enable_standalone_scale_spline=True,\n",
    "        base_activation=nn.ReLU,\n",
    "        grid_eps=0.01,\n",
    "        grid_range=[-1, 1],\n",
    "    ):\n",
    "        super(KANLinear, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.grid_size = grid_size\n",
    "        self.spline_order = spline_order\n",
    "\n",
    "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
    "        grid = (\n",
    "            (\n",
    "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
    "                + grid_range[0]\n",
    "            )\n",
    "            .expand(in_features, -1)\n",
    "            .contiguous()\n",
    "        )\n",
    "        self.register_buffer(\"grid\", grid)\n",
    "\n",
    "        self.base_weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.spline_weight = nn.Parameter(\n",
    "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
    "        )\n",
    "        if enable_standalone_scale_spline:\n",
    "            self.spline_scaler = nn.Parameter(\n",
    "                torch.Tensor(out_features, in_features)\n",
    "            )\n",
    "\n",
    "        self.scale_noise = scale_noise\n",
    "        self.scale_base = scale_base\n",
    "        self.scale_spline = scale_spline\n",
    "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
    "        self.base_activation = base_activation()\n",
    "        self.grid_eps = grid_eps\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
    "        with torch.no_grad():\n",
    "            noise = (\n",
    "                (\n",
    "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
    "                    - 1 / 2\n",
    "                )\n",
    "                * self.scale_noise\n",
    "                / self.grid_size\n",
    "            )\n",
    "            self.spline_weight.data.copy_(\n",
    "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
    "                * self.curve2coeff(\n",
    "                    self.grid.T[self.spline_order : -self.spline_order],\n",
    "                    noise,\n",
    "                )\n",
    "            )\n",
    "            if self.enable_standalone_scale_spline:\n",
    "                nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
    "\n",
    "    def b_splines(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Compute the B-spline bases for the given input tensor.\n",
    "        \"\"\"\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "\n",
    "        grid: torch.Tensor = self.grid\n",
    "        x = x.unsqueeze(-1)\n",
    "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
    "        for k in range(1, self.spline_order + 1):\n",
    "            bases = (\n",
    "                (x - grid[:, : -(k + 1)])\n",
    "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
    "                * bases[:, :, :-1]\n",
    "            ) + (\n",
    "                (grid[:, k + 1 :] - x)\n",
    "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
    "                * bases[:, :, 1:]\n",
    "            )\n",
    "\n",
    "        return bases.contiguous()\n",
    "\n",
    "    def curve2coeff(self, x: torch.Tensor, y: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Compute the coefficients of the curve that interpolates the given points.\n",
    "        \"\"\"\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
    "\n",
    "        A = self.b_splines(x).transpose(0, 1)  # (in_features, batch_size, grid_size + spline_order)\n",
    "        B = y.transpose(0, 1)  # (in_features, batch_size, out_features)\n",
    "        solution = torch.linalg.lstsq(A, B).solution  # (in_features, grid_size + spline_order, out_features)\n",
    "        result = solution.permute(2, 0, 1)  # (out_features, in_features, grid_size + spline_order)\n",
    "\n",
    "        return result.contiguous()\n",
    "\n",
    "    @property\n",
    "    def scaled_spline_weight(self):\n",
    "        return self.spline_weight * (\n",
    "            self.spline_scaler.unsqueeze(-1)\n",
    "            if self.enable_standalone_scale_spline\n",
    "            else 1.0\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.to(self.grid.device)  # Move x to the same device as grid\n",
    "        assert x.size(-1) == self.in_features\n",
    "        original_shape = x.shape\n",
    "        x = x.view(-1, self.in_features)\n",
    "\n",
    "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
    "        spline_output = F.linear(\n",
    "            self.b_splines(x).view(x.size(0), -1),\n",
    "            self.scaled_spline_weight.view(self.out_features, -1),\n",
    "        )\n",
    "        output = base_output + spline_output\n",
    "    \n",
    "        output = output.view(*original_shape[:-1], self.out_features)\n",
    "        return output\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_grid(self, x: torch.Tensor, margin=0.01):\n",
    "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
    "        batch = x.size(0)\n",
    "\n",
    "        splines = self.b_splines(x)  # (batch, in, coeff)\n",
    "        splines = splines.permute(1, 0, 2)  # (in, batch, coeff)\n",
    "        orig_coeff = self.scaled_spline_weight  # (out, in, coeff)\n",
    "        orig_coeff = orig_coeff.permute(1, 2, 0)  # (in, coeff, out)\n",
    "        unreduced_spline_output = torch.bmm(splines, orig_coeff)  # (in, batch, out)\n",
    "        unreduced_spline_output = unreduced_spline_output.permute(1, 0, 2)  # (batch, in, out)\n",
    "\n",
    "        x_sorted = torch.sort(x, dim=0)[0]\n",
    "        grid_adaptive = x_sorted[\n",
    "            torch.linspace(\n",
    "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
    "        grid_uniform = (\n",
    "            torch.arange(\n",
    "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
    "            ).unsqueeze(1)\n",
    "            * uniform_step\n",
    "            + x_sorted[0]\n",
    "            - margin\n",
    "        )\n",
    "\n",
    "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
    "        grid = torch.cat(\n",
    "            [\n",
    "                grid[:1]\n",
    "                - uniform_step\n",
    "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
    "                grid,\n",
    "                grid[-1:]\n",
    "                + uniform_step\n",
    "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
    "            ],\n",
    "            dim=0,\n",
    "        )\n",
    "\n",
    "        self.grid.copy_(grid.T)\n",
    "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
    "\n",
    "    def regularization_loss(self, regularize_activation=1, regularize_entropy=1):\n",
    "        \"\"\"\n",
    "        Compute the regularization loss.\n",
    "        \"\"\"\n",
    "        l1_fake = self.spline_weight.abs().mean(-1)\n",
    "        regularization_loss_activation = l1_fake.sum()\n",
    "        p = l1_fake / regularization_loss_activation\n",
    "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
    "        return (\n",
    "            regularize_activation * regularization_loss_activation\n",
    "            + regularize_entropy * regularization_loss_entropy\n",
    "        )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-24T00:39:43.774224Z",
     "iopub.status.busy": "2024-10-24T00:39:43.773317Z",
     "iopub.status.idle": "2024-10-24T02:35:03.726803Z",
     "shell.execute_reply": "2024-10-24T02:35:03.725495Z",
     "shell.execute_reply.started": "2024-10-24T00:39:43.774180Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_101/2007075971.py:16: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_101/2007075971.py:38: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/tmp/ipykernel_101/2007075971.py:60: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40 | Training Loss: 0.6816 | Validation Loss: 0.4229 | Training Accuracy: 0.7743 | Validation Accuracy: 0.8418 | Epoch Time: 256.34 seconds\n",
      "Epoch 2/40 | Training Loss: 0.3532 | Validation Loss: 0.3529 | Training Accuracy: 0.8713 | Validation Accuracy: 0.8694 | Epoch Time: 178.06 seconds\n",
      "Epoch 3/40 | Training Loss: 0.2696 | Validation Loss: 0.2969 | Training Accuracy: 0.9011 | Validation Accuracy: 0.8919 | Epoch Time: 175.62 seconds\n",
      "Patience counter: 1\n",
      "Epoch 4/40 | Training Loss: 0.2117 | Validation Loss: 0.3022 | Training Accuracy: 0.9240 | Validation Accuracy: 0.8875 | Epoch Time: 178.47 seconds\n",
      "Epoch 5/40 | Training Loss: 0.1686 | Validation Loss: 0.2557 | Training Accuracy: 0.9394 | Validation Accuracy: 0.9115 | Epoch Time: 178.06 seconds\n",
      "Epoch 6/40 | Training Loss: 0.1356 | Validation Loss: 0.2401 | Training Accuracy: 0.9525 | Validation Accuracy: 0.9189 | Epoch Time: 177.93 seconds\n",
      "Epoch 7/40 | Training Loss: 0.1126 | Validation Loss: 0.2359 | Training Accuracy: 0.9600 | Validation Accuracy: 0.9217 | Epoch Time: 175.77 seconds\n",
      "Epoch 8/40 | Training Loss: 0.0935 | Validation Loss: 0.2360 | Training Accuracy: 0.9672 | Validation Accuracy: 0.9246 | Epoch Time: 175.27 seconds\n",
      "Epoch 9/40 | Training Loss: 0.0836 | Validation Loss: 0.2264 | Training Accuracy: 0.9705 | Validation Accuracy: 0.9270 | Epoch Time: 175.37 seconds\n",
      "Patience counter: 1\n",
      "Epoch 10/40 | Training Loss: 0.0758 | Validation Loss: 0.2427 | Training Accuracy: 0.9731 | Validation Accuracy: 0.9239 | Epoch Time: 177.71 seconds\n",
      "Patience counter: 2\n",
      "Epoch 11/40 | Training Loss: 0.0667 | Validation Loss: 0.2327 | Training Accuracy: 0.9767 | Validation Accuracy: 0.9256 | Epoch Time: 174.09 seconds\n",
      "Epoch 12/40 | Training Loss: 0.0604 | Validation Loss: 0.2407 | Training Accuracy: 0.9782 | Validation Accuracy: 0.9289 | Epoch Time: 173.05 seconds\n",
      "Epoch 13/40 | Training Loss: 0.0555 | Validation Loss: 0.2249 | Training Accuracy: 0.9806 | Validation Accuracy: 0.9306 | Epoch Time: 176.49 seconds\n",
      "Epoch 14/40 | Training Loss: 0.0522 | Validation Loss: 0.2448 | Training Accuracy: 0.9814 | Validation Accuracy: 0.9310 | Epoch Time: 180.88 seconds\n",
      "Patience counter: 1\n",
      "Epoch 15/40 | Training Loss: 0.0474 | Validation Loss: 0.2358 | Training Accuracy: 0.9834 | Validation Accuracy: 0.9302 | Epoch Time: 172.29 seconds\n",
      "Patience counter: 2\n",
      "Epoch 16/40 | Training Loss: 0.0465 | Validation Loss: 0.2499 | Training Accuracy: 0.9833 | Validation Accuracy: 0.9298 | Epoch Time: 178.69 seconds\n",
      "Patience counter: 3\n",
      "Epoch 17/40 | Training Loss: 0.0443 | Validation Loss: 0.2569 | Training Accuracy: 0.9842 | Validation Accuracy: 0.9301 | Epoch Time: 172.10 seconds\n",
      "Epoch 18/40 | Training Loss: 0.0405 | Validation Loss: 0.2364 | Training Accuracy: 0.9855 | Validation Accuracy: 0.9336 | Epoch Time: 177.52 seconds\n",
      "Patience counter: 1\n",
      "Epoch 19/40 | Training Loss: 0.0397 | Validation Loss: 0.2535 | Training Accuracy: 0.9862 | Validation Accuracy: 0.9300 | Epoch Time: 175.79 seconds\n",
      "Patience counter: 2\n",
      "Epoch 20/40 | Training Loss: 0.0373 | Validation Loss: 0.2427 | Training Accuracy: 0.9868 | Validation Accuracy: 0.9334 | Epoch Time: 172.59 seconds\n",
      "Epoch 21/40 | Training Loss: 0.0349 | Validation Loss: 0.2544 | Training Accuracy: 0.9872 | Validation Accuracy: 0.9339 | Epoch Time: 174.79 seconds\n",
      "Patience counter: 1\n",
      "Epoch 22/40 | Training Loss: 0.0383 | Validation Loss: 0.2678 | Training Accuracy: 0.9860 | Validation Accuracy: 0.9292 | Epoch Time: 174.01 seconds\n",
      "Epoch 23/40 | Training Loss: 0.0366 | Validation Loss: 0.2401 | Training Accuracy: 0.9864 | Validation Accuracy: 0.9359 | Epoch Time: 175.32 seconds\n",
      "Epoch 24/40 | Training Loss: 0.0328 | Validation Loss: 0.2376 | Training Accuracy: 0.9874 | Validation Accuracy: 0.9363 | Epoch Time: 171.91 seconds\n",
      "Patience counter: 1\n",
      "Epoch 25/40 | Training Loss: 0.0355 | Validation Loss: 0.2572 | Training Accuracy: 0.9871 | Validation Accuracy: 0.9340 | Epoch Time: 176.73 seconds\n",
      "Epoch 26/40 | Training Loss: 0.0315 | Validation Loss: 0.2337 | Training Accuracy: 0.9884 | Validation Accuracy: 0.9388 | Epoch Time: 172.20 seconds\n",
      "Patience counter: 1\n",
      "Epoch 27/40 | Training Loss: 0.0278 | Validation Loss: 0.2396 | Training Accuracy: 0.9895 | Validation Accuracy: 0.9379 | Epoch Time: 173.70 seconds\n",
      "Patience counter: 2\n",
      "Epoch 28/40 | Training Loss: 0.0313 | Validation Loss: 0.2636 | Training Accuracy: 0.9881 | Validation Accuracy: 0.9306 | Epoch Time: 175.17 seconds\n",
      "Patience counter: 3\n",
      "Epoch 29/40 | Training Loss: 0.0299 | Validation Loss: 0.2525 | Training Accuracy: 0.9885 | Validation Accuracy: 0.9365 | Epoch Time: 173.41 seconds\n",
      "Patience counter: 4\n",
      "Epoch 30/40 | Training Loss: 0.0302 | Validation Loss: 0.2396 | Training Accuracy: 0.9882 | Validation Accuracy: 0.9380 | Epoch Time: 172.80 seconds\n",
      "Patience counter: 5\n",
      "Epoch 31/40 | Training Loss: 0.0291 | Validation Loss: 0.2393 | Training Accuracy: 0.9889 | Validation Accuracy: 0.9384 | Epoch Time: 172.64 seconds\n",
      "Epoch 32/40 | Training Loss: 0.0256 | Validation Loss: 0.2428 | Training Accuracy: 0.9903 | Validation Accuracy: 0.9393 | Epoch Time: 177.22 seconds\n",
      "Patience counter: 1\n",
      "Epoch 33/40 | Training Loss: 0.0263 | Validation Loss: 0.2706 | Training Accuracy: 0.9903 | Validation Accuracy: 0.9330 | Epoch Time: 174.12 seconds\n",
      "Patience counter: 2\n",
      "Epoch 34/40 | Training Loss: 0.0255 | Validation Loss: 0.2680 | Training Accuracy: 0.9901 | Validation Accuracy: 0.9370 | Epoch Time: 175.26 seconds\n",
      "Patience counter: 3\n",
      "Epoch 35/40 | Training Loss: 0.0298 | Validation Loss: 0.2530 | Training Accuracy: 0.9884 | Validation Accuracy: 0.9367 | Epoch Time: 174.61 seconds\n",
      "Patience counter: 4\n",
      "Epoch 36/40 | Training Loss: 0.0233 | Validation Loss: 0.2457 | Training Accuracy: 0.9913 | Validation Accuracy: 0.9367 | Epoch Time: 175.83 seconds\n",
      "Patience counter: 5\n",
      "Epoch 37/40 | Training Loss: 0.0241 | Validation Loss: 0.2721 | Training Accuracy: 0.9908 | Validation Accuracy: 0.9327 | Epoch Time: 174.02 seconds\n",
      "Patience counter: 6\n",
      "Epoch 38/40 | Training Loss: 0.0239 | Validation Loss: 0.2822 | Training Accuracy: 0.9905 | Validation Accuracy: 0.9324 | Epoch Time: 174.85 seconds\n",
      "Patience counter: 7\n",
      "Early stopping at epoch 39\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Modify the classifier for the number of classes\n",
    "num_classes = len(train_dataset.classes)\n",
    "model.fc =KANLinear(in_features=model.fc.in_features, out_features=num_classes)\n",
    "\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Use mixed precision training\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Define early stopping parameters\n",
    "best_val_accuracy = float('-inf')\n",
    "patience_counter = 0\n",
    "patience = 7\n",
    "\n",
    "# Training and validation\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    total_train = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Mixed precision training\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        train_correct += torch.sum(preds == labels).item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    total_val = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += torch.sum(preds == labels).item()\n",
    "            total_val += labels.size(0)\n",
    "\n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    train_accuracy = train_correct / total_train\n",
    "    val_accuracy = val_correct / total_val\n",
    "\n",
    "    # Early Stopping\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f'Patience counter: {patience_counter}')\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "\n",
    "    # Display metrics\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | \"\n",
    "      f\"Training Loss: {avg_train_loss:.4f} | \"\n",
    "      f\"Validation Loss: {avg_val_loss:.4f} | \"\n",
    "      f\"Training Accuracy: {train_accuracy:.4f} | \"\n",
    "      f\"Validation Accuracy: {val_accuracy:.4f} | \"\n",
    "      f\"Epoch Time: {epoch_time:.2f} seconds\")\n",
    "    \n",
    "    # Clear cache and reset start time\n",
    "    torch.cuda.empty_cache()\n",
    "    start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5467708,
     "sourceId": 9065893,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
